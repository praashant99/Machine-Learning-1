{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer,LabelEncoder\n",
    "from scipy.stats import norm, skew\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the following functions as per the description, so that they can be called later to perform the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to treat missing values\n",
    "\n",
    "def treat_null_values(df, method):\n",
    "    \"\"\"Treats the missing values in the dataframe.\n",
    "    \n",
    "    This function accepts a dataframe and the method to treat the missing value.\n",
    "    Depending on the method passed, impute/drop the missing values.\n",
    "        \n",
    "    Keyword arguments:\n",
    "    df -- pandas dataframe for which we want to treat the missing values\n",
    "    method -- method to treat the missing values\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'drop':\n",
    "        df.dropna(inplace = True)\n",
    "    elif method == 'mean':\n",
    "        df.fillna(round(df.mean(),1), inplace = True)\n",
    "    elif method == 'median':\n",
    "        df.fillna(df.median(), inplace = True)\n",
    "    elif method == 'mode':\n",
    "        df.fillna(df.mode()[0], inplace = True)\n",
    "    else:\n",
    "        df.fillna('NA', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to seperate the numerical and categorical columns\n",
    "\n",
    "def num_and_cat_columns(df):\n",
    "    \"\"\"Return seperate list of numerical & categorical columns.\n",
    "    \n",
    "    This function accepts a dataframe and returns two lists,\n",
    "    one containing the names of numerical columns(num_cols) and the other categorical columns(cat_cols).\n",
    "        \n",
    "    Keyword arguments:\n",
    "    df -- pandas dataframe for which we want the list of columns\n",
    "    \n",
    "    Returns:\n",
    "    num_cols -- list of numerical columns\n",
    "    cat_cols -- list of categorical columns\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    cols = df.columns\n",
    "    num_cols = df._get_numeric_data().columns\n",
    "    cat_cols = list(set(cols) - set(num_cols))\n",
    "    \n",
    "    return num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to encode the categorical column so as to convert them to numeric.\n",
    "    \n",
    "def encode_category(df, enc, col, method):\n",
    "    \"\"\"Encodes the categorical columns of the dataframe.\n",
    "    \n",
    "    This function accepts a dataframe and columns to be encoded along with the method to be used for encoding.\n",
    "        \n",
    "    Keyword arguments:\n",
    "    df -- pandas dataframe for which we want to encode the columns -- this dataframe would be transformed\n",
    "    enc -- the encoder - fitted on the train data\n",
    "    col -- list of columns that is to be encoded\n",
    "    method -- method to be used while encoding\n",
    "    \n",
    "    Returns:\n",
    "    df1 -- the encoded dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'label':\n",
    "        # lb = LabelEncoder()\n",
    "        # lb.fit(df[col])\n",
    "        df[col] = enc.transform(df[col].astype(str))\n",
    "    \n",
    "    elif method == 'onehot':\n",
    "        # ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        # ohe.fit(df[[col]])\n",
    "        tempdf = enc.transform(df[[col]]).toarray()\n",
    "        newdf = pd.DataFrame(tempdf, columns = np.array(ohe.categories_).ravel())\n",
    "        df = pd.concat([df, newdf], axis=1)\n",
    "        df.drop(columns=[col], inplace = True)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clean the dollar sign from the currency column & convert it to float.\n",
    "    \n",
    "def clean_dollar(df, col):\n",
    "    \"\"\"Removes \"$\" sign from a column & converts it to float.\n",
    "    \n",
    "    This function accepts a dataframe and columns with $ sign to be converted to float.\n",
    "        \n",
    "    Keyword arguments:\n",
    "    df -- pandas dataframe for which we want to encode the columns\n",
    "    col -- list of columns that is to be converted\n",
    "    \n",
    "    Returns:\n",
    "    df -- the converted dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df[col] = df[col].apply(lambda s: s.strip('$')).astype(float)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize distributions of the column(s) by plotting them.\n",
    "    \n",
    "def plot_distribution(kind_, df, *col):\n",
    "    \"\"\"Plot distribution of the column(s).\n",
    "    \n",
    "    This function will plot a chart of the passed column as the 'kind' specified in kind_.\n",
    "    You can pass multiple columns to this function.\n",
    "        \n",
    "    Keyword arguments:\n",
    "    knid_ -- 'kind' of chart that will be plotted\n",
    "    df -- pandas dataframe which has the data\n",
    "    *col -- list of all the features for which we want to plot the distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    if kind_ == 'box':\n",
    "        \n",
    "        if len(col) == 1:\n",
    "            boxplot = df.boxplot(column = col[0], rot = 90)\n",
    "            plt.show()\n",
    "        \n",
    "        elif len(col) > 1:\n",
    "            for c in col[1:]:\n",
    "                boxplot = df.boxplot(column = col[0], by = c, rot = 90)\n",
    "            plt.show()\n",
    "        \n",
    "    else:\n",
    "        if len(col) == 0:\n",
    "            df.plot(kind = kind_)\n",
    "            plt.show()\n",
    "        \n",
    "        elif len(col) == 1:\n",
    "            df[col[0]].plot(kind = kind_)\n",
    "            plt.xlabel(col[0])\n",
    "            plt.show()\n",
    "        \n",
    "        elif len(col) == 2:\n",
    "            df.plot(x = col[0], y = col[1], kind = kind_)\n",
    "            plt.xlabel(col[0])\n",
    "            plt.ylabel(col[1])\n",
    "            plt.show()\n",
    "        \n",
    "        else:\n",
    "            print(\"Unable to plot a chart with given parameters.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to apply transformation to any column\n",
    "\n",
    "def transform_column(df, col, transformation):\n",
    "    \"\"\"Apply transformation to the column(s).\n",
    "    \n",
    "    This function will apply the passed transformation to the given dataframe & columns.\n",
    "    You can pass multiple columns to this function.\n",
    "        \n",
    "    Keyword arguments:\n",
    "    df -- pandas dataframe which has the data\n",
    "    col -- list of all the features for which we want to apply the transformation\n",
    "    transformation -- the transformation we want to apply\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if transformation == 'log':\n",
    "        df = np.log(df)\n",
    "        \n",
    "    elif transformation == 'square':\n",
    "        df = np.square(df)\n",
    "        \n",
    "    elif transformation == 'sqrt':\n",
    "        df = np.sqrt(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check outliers using box plot\n",
    "\n",
    "def check_outliers(df, col, cat):\n",
    "    \"\"\"Check outliers through boxplot.\n",
    "    \n",
    "    This function plots and displays the boxplot of the feature col vs all the categories defined. \n",
    "    Check for any outlier present.\n",
    "        \n",
    "    Keyword arguments:\n",
    "    df -- pandas dataframe which has the data\n",
    "    col -- the feature for which we want to plot the boxplot\n",
    "    cat -- the list of features (categorical) by which we want to check the outliers (for each category in each feature)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(cat) == 0:\n",
    "        boxplot = df.boxplot(column=[col], rot = 90)\n",
    "    else:\n",
    "        for c in cat:\n",
    "            boxplot = df.boxplot(column=[col], by=[c], rot = 90)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fit the model & return the score\n",
    "\n",
    "def fit_model(X_train, X_test, y_train, y_test, model):\n",
    "    \"\"\"Fit the model & return the score of the fitted model.\n",
    "    \n",
    "    This function accepts the test & train data and fits the given model to it and returns the score of the model.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    X_train -- Train feature\n",
    "    X_test -- Test/Validation feature\n",
    "    y_train -- Train target\n",
    "    y_test -- Tets/Validation target\n",
    "    model -- the model to be fitted\n",
    "    \n",
    "    Returns:\n",
    "    r2 -- R-Square of the fitted model    \n",
    "    \"\"\"\n",
    "        \n",
    "    if model == 'LinearRegression':\n",
    "        \n",
    "        regressor=LinearRegression()\n",
    "        regressor.fit(X_train,y_train)\n",
    "        y_pred =regressor.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "    elif model == 'Lasso':\n",
    "        \n",
    "        lasso = Lasso()\n",
    "        lasso.fit(X_train, y_train)\n",
    "        lasso_pred = lasso.predict(X_test)\n",
    "        r2 = r2_score(y_test, lasso_pred)\n",
    "\n",
    "    elif model == 'Ridge':\n",
    "        \n",
    "        ridge = Ridge()\n",
    "        ridge.fit(X_train, y_train)\n",
    "        ridge_pred = ridge.predict(X_test)\n",
    "        r2 = r2_score(y_test, ridge_pred)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2= r2_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "    return r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset. Take a look at the dataset. \n",
    "\n",
    "* Check the data types present in the dataframe.\n",
    "* Call the num_and_cat_columns() with train as the parameter and store the results.\n",
    "* Are there any missing values? Are there any Outliers? How do you want to treat them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"..//Data//train.csv\")\n",
    "print(train.head())\n",
    "\n",
    "#Split the data into X and Y\n",
    "X = train.drop(columns = ['Total Compensation'])\n",
    "y = train[['Total Compensation']]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "\n",
    "a, b = num_and_cat_columns(X)\n",
    "print(a,len(a))\n",
    "print(b, len(b))\n",
    "\n",
    "\n",
    "\n",
    "print(X.isnull().sum())\n",
    "check_outliers(y, 'Total Compensation', [])\n",
    "\n",
    "\n",
    "X.drop(columns = ['Department'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "- Check for the categorical & continuous features. \n",
    "- Check out the best plots for plotting between categorical target and continuous features and try making some inferences from these plots.\n",
    "- Clean the data and apply some data preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the features, check the type where any currency is involved. \n",
    "# We have columns with compensations stored in form of strings. We need to clean it and convert this to numeric. \n",
    "# Call the clean_dollar() to do the same. Apply it to all train, val & test data.\n",
    "\n",
    "\n",
    "for c in ['Retirement', 'Health and Dental', 'Other Benefits']:\n",
    "    X = clean_dollar(X, c)\n",
    "    # X_test = clean_dollar(X_test, c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of certain columns you might find of interest. \n",
    "# This can be done by calling the plot_distribution(). \n",
    "# Apply some good transformation if required. Call transform_column() to do the same.\n",
    "\n",
    "plot_distribution('hist', X, 'Retirement')\n",
    "plot_distribution('hist', X, 'Health and Dental')\n",
    "plot_distribution('hist', X, 'Other Benefits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the null values by calling the treat_null_values()\n",
    "\n",
    "treat_null_values(X['Union'], 'mode')\n",
    "treat_null_values(X['Job'], 'mode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we proceed with the model fitting, we need to get rid of the categorical columns.\n",
    "# We can use One Hot Encoding or Label Encoding to convert the categorical columns to numeric.\n",
    "# Call the encode_category() with the list of columns and the method of encoding to do the same.\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0,test_size=0.2)\n",
    "X_train_ = X_train.copy()  # Create a copy of the train data to train the encoder\n",
    "\n",
    "\n",
    "for col in ['Union', 'Job Family', 'Job', 'Year Type', 'Organization Group']:\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(X_train_[col]) \n",
    "    X_test = encode_category(X_test, lb, col, 'label')\n",
    "    X_train = encode_category(X_train, lb, col, 'label')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now since we have encoded all the categorical columns, there shouldn't be any left in the data.\n",
    "# Check the same by calling num_and_cat_columns()\n",
    "\n",
    "\n",
    "a, b = num_and_cat_columns(X_train)\n",
    "print(\"Numerical Columns:\", a,len(a))\n",
    "print(\"Categorical Columns:\", b, len(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "- Separate the features and target and then split the train data into train and validation set.\n",
    "- Now let's come to the actual task, using linear regression, predict the `Total Compensation`. \n",
    "- Try improving upon the `r2_score` (R-Square) using different parameters that give the best score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's come to the actual task, using linear regression to predict the Total Compensation. \n",
    "# We will check the model accuracy using `r^2 score`\n",
    "# Call the fit_model() with respective parameters.\n",
    "\n",
    "r2 = fit_model(X_train, X_test, y_train, y_test, 'LinearRegression')\n",
    "print (\"Linear Regression: \", r2)\n",
    "\n",
    "\n",
    "# # Check if the accuracy increases after using the Lasso Regularization technique.\n",
    "# # Call the fit_model() with respective parameters.\n",
    "r2 = fit_model(X_train, X_test, y_train, y_test, 'Lasso')\n",
    "print (\"Lasso: \", r2)\n",
    "\n",
    "\n",
    "# # Check if the accuracy increases after using the Ridge Regularization technique.\n",
    "# # Call the fit_model() with respective parameters.\n",
    "\n",
    "r2 = fit_model(X_train, X_test, y_train, y_test, 'Ridge')\n",
    "print (\"Ridge: \", r2)\n",
    "\n",
    "\n",
    "\n",
    "# Check if the accuracy increases after using the Polypipeline technique.\n",
    "r2 = fit_model(X_train, X_test, y_train, y_test, 'Pipeline')\n",
    "print (\"Pipeline: \", r2)\n",
    "\n",
    "# Which technique was the best? That is your final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test data and creating the sample submission file.\n",
    "\n",
    "- Load the test data and store the `Id` column in a separate variable.\n",
    "- Perform the same operations on the test data that you have performed on the train data.\n",
    "- Create the submission file as a `csv` file consisting of the `Id` column from the test data and your prediction as the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "# Prediction on test data\n",
    "\n",
    "# Read the test data\n",
    "test = pd.read_csv('..//Data//test.csv')\n",
    "\n",
    "# Storing the id from the test file\n",
    "id_ = test['Id']\n",
    "\n",
    "# Dropping the same columns from the test data and applying same transformation\n",
    "test.drop(columns = ['Department'], inplace = True)\n",
    "treat_null_values(test['Union'], 'mode')\n",
    "treat_null_values(test['Job'], 'mode')\n",
    "\n",
    "for c in ['Retirement', 'Health and Dental', 'Other Benefits']:\n",
    "    test = clean_dollar(test, c)\n",
    "    \n",
    "for col in ['Union', 'Job Family', 'Job', 'Year Type', 'Organization Group']:\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(X_train_[col])\n",
    "    test = encode_category(test, lb, col, 'label')\n",
    "    \n",
    "   \n",
    "# Applying pipeline on test data\n",
    "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test = model.predict(test)\n",
    "y_pred_test = y_pred_test.flatten()\n",
    "\n",
    "# Create a sample submission file\n",
    "sample_submission = pd.DataFrame({'Id':id_,'Total Compensation':y_pred_test})\n",
    "\n",
    "# Convert the sample submission file into a csv file\n",
    "sample_submission.to_csv('sample_submission_test.csv',index=False)\n",
    "\n",
    "# Code ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
