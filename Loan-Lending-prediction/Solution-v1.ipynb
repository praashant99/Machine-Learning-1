{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the following functions as per the description, so that they can be called later to perform the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated features\n",
    "\n",
    "def remove_corelated_features(X_train,val):\n",
    "    \"\"\" Function to remove the correlated features\n",
    "    \n",
    "    This function accepts the dataframe X_train,val which creates a correlation matix and removes \n",
    "    the correlated features based on certain threshold.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    X_train - Pandas dataframe which contains the independent features.\n",
    "    val - Certain threshold value by which correlated features to be dropped.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.75\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > val)]\n",
    "    print(\"Columns to be dropped: \",to_drop)\n",
    "    \n",
    "    return X_train.drop(to_drop,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of the passed features\n",
    "    \n",
    "def cal_eval_metric(y_test, y_pred, metric):\n",
    "    \"\"\"  Check the distribution of the passed features\n",
    "    \n",
    "    This function will check for the metric passed(accuracy/precision/recall/f1/confusion matrix) \n",
    "    and return the required value.\n",
    "    \n",
    "    Keyword Arguments:   \n",
    "    y_test: actual target values\n",
    "    y_pred: predicted target values\n",
    "    metric: the metric to be calculated\n",
    "    \n",
    "    \"\"\"\n",
    "    if metric == 'accuracy':\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    elif metric == 'precision':\n",
    "        score = precision_score(y_test, y_pred)\n",
    "    \n",
    "    elif metric == 'recall':\n",
    "        score = recall_score(y_test, y_pred)\n",
    "    \n",
    "     \n",
    "    elif metric == 'f1':\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        \n",
    "    elif metric == 'roc_auc':\n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        \n",
    "    else:\n",
    "        print(\"Please enter proper score metric.\")\n",
    "\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset. Take a look at the dataset. \n",
    "\n",
    "* Check the data types present in the dataframe.\n",
    "* Call the num_and_cat_columns() with train as the parameter and store the results.\n",
    "* Are there any missing values? Are there any Outliers? How do you want to treat them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  loan_amnt  funded_amnt  term  int_rate  installment  grade  emp_title  \\\n",
      "0   0    27000.0      27000.0     1       141       805.68      6     100315   \n",
      "1   1    15000.0      15000.0     0        77       551.36      3      94083   \n",
      "2   2     7000.0       7000.0     0         8       222.28      0      64843   \n",
      "3   3    18950.0      18950.0     0        38       648.50      1      54947   \n",
      "4   4    35000.0      35000.0     1       108       976.04      4      56326   \n",
      "\n",
      "   home_ownership  annual_inc  ...  total_rec_late_fee  recoveries  \\\n",
      "0               4    120000.0  ...                 0.0         0.0   \n",
      "1               0    100000.0  ...                 0.0         0.0   \n",
      "2               0     48000.0  ...                 0.0         0.0   \n",
      "3               4     54000.0  ...                 0.0         0.0   \n",
      "4               0     87000.0  ...                 0.0         0.0   \n",
      "\n",
      "   collection_recovery_fee  last_pymnt_amnt  collections_12_mths_ex_med  \\\n",
      "0                      0.0         24502.20                         0.0   \n",
      "1                      0.0           838.69                         0.0   \n",
      "2                      0.0          5097.27                         0.0   \n",
      "3                      0.0          4407.62                         0.0   \n",
      "4                      0.0         17284.95                         0.0   \n",
      "\n",
      "   acc_now_delinq  tot_coll_amt  tot_cur_bal  total_rev_hi_lim  loan_status  \n",
      "0             0.0           0.0      48614.0           27900.0            0  \n",
      "1             0.0           0.0      47703.0           17000.0            0  \n",
      "2             0.0           0.0     138287.0           19500.0            0  \n",
      "3             0.0           0.0      75286.0           42800.0            0  \n",
      "4             0.0           0.0     213561.0           52000.0            0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "- Check for the categorical & continuous features. \n",
    "- Check out the best plots for plotting between categorical target and continuous features and try making some inferences from these plots.\n",
    "- Clean the data and apply some data preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be dropped:  ['funded_amnt', 'installment', 'grade', 'collection_recovery_fee', 'total_rev_hi_lim']\n"
     ]
    }
   ],
   "source": [
    "# Now, check the correlation. \n",
    "# For highly correlated features adds no extra information to the model, we will drop the columns that are highly correlated with others.\n",
    "# Call remove_correlated_features() with the threshold value 0.75 to be dropped.\n",
    "\n",
    "# You can play with different threshold value and see how it affects on the score.\n",
    "\n",
    "train = remove_corelated_features(train, 0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "- Separate the features and target and then split the train data into train and validation set.\n",
    "- Now let's come to the actual task, using linear regression, predict the `Total Compensation`. \n",
    "- Try improving upon the `r2_score` (R-Square) using different parameters that give the best score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Accuracy Score:  0.9573875857182621\n",
      "Precision Score:  0.9925229651783807\n",
      "Recall Score:  0.7380460683081811\n",
      "F1 Score:  0.8465743440233235\n",
      "Roc Auc Curve:  0.8684963064873437\n",
      "Highest F1 Score is: 0.9532834580216127 with features= 5\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test\n",
    "X = train.drop(columns = ['loan_status'])\n",
    "y = train[['loan_status']]\n",
    "\n",
    "print(y['loan_status'].unique())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Now let's come to the actual task, using logistic regression to predict the loan_status. \n",
    "# fit the model and predit the target values\n",
    "\n",
    "#Instantiate logistic regression model\n",
    "L_regressor=LogisticRegression()\n",
    "\n",
    "# fit the model on train data\n",
    "L_regressor.fit(X_train, y_train)\n",
    "\n",
    "# predict the result\n",
    "y_pred =L_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "# We will check the model accuracy using `accuracy score`, `precision score`, `recall score`, and `f1 score`. \n",
    "# To see your model's performance, call the cal_eval_metric() with respective parameters.\n",
    "\n",
    "accuracy= cal_eval_metric(y_test,y_pred,  'accuracy')\n",
    "precision = cal_eval_metric(y_test,y_pred,  'precision')\n",
    "recall = cal_eval_metric(y_test,y_pred,  'recall')\n",
    "f1 = cal_eval_metric(y_test,y_pred,  'f1')\n",
    "roc_auc= cal_eval_metric(y_test,y_pred,  'roc_auc')\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy)\n",
    "print(\"Precision Score: \", precision)\n",
    "print(\"Recall Score: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "print(\"Roc Auc Curve: \", roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lets apply a feature selection technique(Recursive Feature Elimination test)to see whether we can increase our score.\n",
    "# Create a list of the number of features and call transform the dataset to train the model.\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "high_score = 0  \n",
    "nof = 0\n",
    "nof_list=[5,10,15,20,25]\n",
    "    \n",
    "for n in nof_list:\n",
    "    test_ = RFE(model,n)\n",
    "    X_train = test_.fit_transform(X_train,y_train)\n",
    "    X_test = test_.transform(X_test)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_pred,y_test)\n",
    "    \n",
    "    if score > high_score:\n",
    "        high_score = score\n",
    "        nof = n\n",
    "        test_best = test_ # store the model with best score to make prediction on the test data\n",
    "        \n",
    "print(\"Highest F1 Score is:\",high_score, \"with features=\",nof)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test data and creating the sample submission file.\n",
    "\n",
    "- Load the test data and store the `Id` column in a separate variable.\n",
    "- Perform the same operations on the test data that you have performed on the train data.\n",
    "- Create the submission file as a `csv` file consisting of the `Id` column from the test data and your prediction as the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "# Prediction on test data\n",
    "\n",
    "# Read the test data\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Storing the id from the test file\n",
    "id_ = test['Id']\n",
    "\n",
    "# Dropping the same columns from the test data and applying same transformation\n",
    "\n",
    "test = test.drop(['funded_amnt', 'installment', 'grade', 'collection_recovery_fee', 'total_rev_hi_lim'],axis=1)\n",
    "\n",
    "test = test_best.transform(test)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test = model.predict(test)\n",
    "y_pred_test = y_pred_test.flatten()\n",
    "\n",
    "# Create a sample submission file\n",
    "sample_submission = pd.DataFrame({'Id':id_,'loan_status':y_pred_test})\n",
    "\n",
    "# Convert the sample submission file into a csv file\n",
    "# sample_submission.to_csv('sample_submission.csv',index=False)\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
